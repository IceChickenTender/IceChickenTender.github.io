---
title: "[LLM/RAG] LLM Application - 6. Vecotr Database에 대해서 알아보자"
categories:
  - LLM/RAG

tags:
  - LLM/RAG
  
use_math: true  
toc: true
toc_sticky: true
toc_label: "Vector Database에 대해서 알아보자"
---

# 개요

이전 "LLM Application 개발하기" 포스트에서 RAG에 대해서 알아보고 RAG를 직접 구축하면서 크로마 DB와 벡터 연산 라이브러리인 메타의 Faiss를 활용해 벡터 검색을 구현해 보았습니다. 하지만 그 땐 간단하게 사용만 해보고 벡터 DB가 정확히 무엇인지까지 다루진 않았습니다. 이번 포스트에서는 벡터 DB에 대해서 자세히 다뤄보도록 하겠습니다.

먼저 벡터 DB가 등장한 배경을 딥러닝의 발전과 관련하여 살펴보도록 하겠습니다. 그리고 Chat-GPT의 출시 이후 벡터 DB에 대한 관심이 높아지면서 선택할 수 있는 벡터 DB의 수가 빠르게 늘고 있습니다. 벡터 DB를 어떻게 구분할 수 있는지, 자신에게 맞는 벡터 DB를 선택하기 위한 기준에 대해서 알아보도록 하겠습니다.

이후 벡터 DB의 작동 원리를 알아보도록 하겠습니다. ANN(Approximate Nearest Neighbor) 검색 방식과 다양한 ANN 검색 알고리즘 중에서 가장 많이 활용되는 HNSW(Hierarchical Navigable Small World) 알고리즘을 자세히 살펴보도록 하겠습니다.

마지막으로 파인콘(Pineconde)의 사용법을 알아보고, 파인콘을 활용해 이미지와 텍스트를 교차 검색할 수 있는 멀티 모달 검색을 구현해 보도록 하겠습니다. 다음은 실습에 사용할 라이브러리의 리스트입니다. 실습 전에 자신의 환경에 설치해 주시기 바랍니다.

```
pineconde-client sentence-transformers datasets faiss-cpu transformers openai
```

# 1. 벡터 DB란

벡터 DB란 벡터 임베딩을 키로 사용하는 DB를 말합니다. 모든 데이터는 적절한 임베딩 모델만 있다면 임베딩으로 변환할 수 있는데 텍스트, 이미지, 음성과 같은 비정형 데이터는 물론 서비스에서 판매하는 상품이나 서비스를 사용하는 사용자도 임베딩 모델을 통해 벡터로 표현할 수 있습니다. 데이터를 적절한 임베딩 모델을 통해 임베딩 벡터로 변환했다면 이제 벡터 DB에 저장하고 임베딩 벡터의 거리 계산을 통해 유사하거나 관련이 깊은 데이터를 검색할 수 있습니다. 벡터 DB는벡터 사이의 거리 계산에 특화된 DB라고 할 수 있습니다.

우선 벡터 DB가 등장한 배경을 딥러닝의 발전과 관련해서 살펴보고, 벡터 DB가 조명 받고 있는 이유에 대해서도 간단히 알아보도록 하겠습니다. 또한 다양한 벡터 DB가 쏘아지고 있는 현재 상황에서 이 분야의 지형을 파악하고 자신에게 맞는 DB를 선태갛기 위한 기준에 대해서도 알아보도록 하겠습니다.

## 1.1 딥러닝과 벡터 DB

벡터 DB의 등장은 딥러닝의 발전과 관련이 깊습니다. 딥러닝은 기존의 머신러닝과 달리 텍스트, 이미지, 오디오와 같은 비정형 데이터를 잘 처리한다는 강점이 있었습니다. 머신러닝과 딥러닝의 차이점은 머신러닝은 사람이 직접 데이터에서의 특징을 추출해 추출한 특징을 사람이 직접 반영해야 하는 것이고, 딥러닝은 학습을 통해 학습 데이터에서 나타나는 특징을 모델이 알아서 반영한다는 것입니다. 그리고 딥러닝은 이러한 특징을 모델 내부의 벡터 값에 반영이 된다는 특징이 있어 대량의 학습 데이터만 준비하면 오랜 기간 작업자가 직접 특징을 정의하지 않고도 학습을 수행할 수 있고 대부분 뛰어난 성능을 보여줘 많은 관심을 받았습니다.

딥러닝 모델은 학습을 하면서 모델 내부에 있는 벡터의 값이 변하게 되는데 우리는 이 벡터를 임베딩으로 사용합니다. 이때 딥러닝 모델에서 학습이 되면서 벡터 값은 비슷한 데이터는 가깝게 있고, 다른 데이터는 멀리 위치하게 되는 특징을 가지게 됩니다. 이러한 임베딩 벡터의 특징을 이용하면 임베딩 벡터 사이의 거리를 계산해서 서로 비슷한 데이터를 찾을 수 있습니다. 벡터 DB는 이런 임베딩 벡터의 특징을 이용하기 위한 목적으로 개발되었습니다. 이런 벡터 DB를 활용하기 위한 단계는 3가지로 나뉩니다.

1. 저장: 저장할 데이터를 임베딩 모델을 거쳐 벡터로 변환하고 벡터 DB에 저장한다.
2. 검색: 검색할 데이터를 임베딩 모델을 거쳐 벡터로 변환하고 벡터 DB에서 검색한다.
3. 결과 반환: 벡터 DB에서는 검색 쿼리의 임베딩과 거리가 가까운 벡터를 찾아 반환한다.

이 방식을 사용하면 검색 쿼리와 가장 가까운 벡터를 찾을 수 있는데, 가장 가까운 벡터는 가장 유사한 데이터를 의미합니다. 그리고 벡터 사이의 거리를 측정하는 다양한 방법이 있는데, 일반적으로 유클리드 거리, 코사인 유사도, 내적을 가장 많이 활용합니다. 딥런이 기술이 폭넓게 활용되면서 데이터의 특징을 추출한 임베딩을 활용하는 경우가 많아졌고, 임베딩을 저장하고 관리하는 기능에 특화된 벡터 DB의 필요성이 커지면서 벡터 DB가 등장했습니다. 대표적으로 이미지 검색과 같이 비정형 데이터의 유사성을 기반으로 검색을 제공하는 서비스나 사용자가 구매한 상품과 유사한 상품을 추천하는 추천 시스템을 구현할 때 벡터 임베딩을 활용합니다.

## 1.2 벡터 DB 지형 파악하기

벡터 임베딩을 저장하고 검색하는 기능을 구현하려고 할 때 다양한 소프트웨어를 접하게 됩니다. 이때 만나는 소프트웨어는 크게 세 가지로 구분할 수 있습니다. 먼저 벡터 라이브러리는 벡터를 저장하고 검색하는 핵심 기능을 구현한 구현체라고 할 수 있습니다. 두 번째로 벡터 전용 DB로 파인콘(Pineconde), 위비에이트(Weaviate), 밀버스(Milvus), 크로마(Chroma) 등이 있습니다. 마지막으로 기존의 DB에 벡터 저장과 검색 기능을 추가한 DB가 있습니다. 가장 유명한 것으로는 엘라스틱서치(Elasticsearch), PostgreSQL, MongoDB, Neo4j 등이 있습니다.

벡터를 제공한다는 점에서 벡터 라이브러리와 벡터 DB의 차이가 그렇게 커 보이진 않습니다. 그렇다면 벡터 라이브러리와 벡터 DB의 차이점은 무엇인지 한 번 알아보도록 하겠습니다. 다음은 벡터 라이브러리에서 제공하지 않는 벡터 DB에서 제공해 주는 기능들입니다.

- 메타 데이터의 저장 및 필터링 기능
- 데이터의 백업 및 관리
- 모니터링, 관련 AI 도구 등 에코시스템과의 통합
- 데이터 보안과 액세스 관리

따라서 간단히 벡터 저장과 검색 기능을 구현하거나 벡터 DB가 제공하는 부가 기능이 필요하지 않은 경우 벡터 라이브러리를 통해 벡터 연산을 수행해도 괜찮지만 그렇지 않다면 벡터 DB를 활용하는 것이 좋습니다.

이제 DB로 좁혀 지형을 파악하자면 아래 그림과 같이 구분할 수 있습니다.

<div align="center">
  <img src="/assets/images/llm_rag/llm_application/5/vector_db_classification.png" width="50%" height="40%"/>
  <figcaption>그림 1 벡터 DB 구분</figcaption>
</div>

벡터 DB 도입을 고려하는 경우 그림 1의 기준을 통해 네 가지로 경우를 나눠 선택할 수 있습니다. 먼저, 고급 벡터 검색이 필요하고 워크로드가 큰(데이터 수, 차원 수 등) 경우 그림 왼쪽의 벡터 전용 DB를 선택하는 것이 좋습니다. 벡터 전용 DB는 벡터 저장과 검색 관련 기능과 그 최적화에 집중하기 때문에 벡터 데이터 처리에 더 뛰어난 경우가 많습니다. 다음으로 벡터 DB에 대해 이해도가 있고 직접 오픈소스 서비스를 활용해 시스템을 구축할 수 있고 선호한다면, 그림 왼쪽 위의 오픈 소스 벡터 DB가 좋은 선택이 될 수 있습니다. 만약 그렇지 않다면 제품 형태로 제공하는 그림 왼쪽 아래의 벡터 DB를 활용하는 것이 좋습니다.

그림 오른쪽의 벡터 기능을 추가한 DB의 경우 벡터 이외의 데이터 형태를 처리할 수 있다는 점에서 벡터 전용 DB에 비해 PostgreSQL, 엘라스틱서치, 레디스 등은 더 오랜 역사를 지니고 있고 엔터프라이즈 규모에서 필요한 다양한 기능을 갖추고 있습니다. 따라서 벡터 검색 기능을 무겁게 사용하지 않고 기존에 이미 도입한 DB가 있는 경우 해당 DB가 벡터 기능을 지원하는지 확인해 활용하는 것이 좋은 선택일 수 있습니다.

# 2. 벡터 DB 작동 원리

벡터 DB는 벡터 사이의 거리를 계산해서 유사한 벡터를 찾습니다. 벡터 사이의 거리를 계산해 유사한 벡터를 찾는 가장 근본적인 방법은 KNN(K-Nearest Neighbor) 검색으로 저장된 모든 임베딩 벡터를 조사해 가장 유사한 K개의 벡터를 반환하는 방법입니다. 간단한 실습으로 KNN 검색 방식의 한계를 알아보고, 그 한계를 극복하기 위해 사용되는 ANN(Approxiamte Nearest Neighbor) 알고리즘이 무엇인지 살펴봅니다. 그리고 가장 대표적인 ANN 알고리즘 중 하나인 HNSW의 원리를 소개합니다.

## 2.1 KNN 검색과 그 한계

KNN 검색은 검색하려는 벡터와 가장 가까운 K개의 이웃 벡터를 찾는 검색 방식입니다. KNN은 직관적이고 모든 데이터를 조사하기 때문에 정확하다는 장점이 있지만 모든 벡터를 조사하기 때문에 연산량이 데이터 수에 비례하게 늘어나 속도가 느려지기 때문에 확장성이 떨어진다는 한계가 있습니다. 이를 확인하기 위해 실습에서 100만 개의 128차원 임베딩 데이터인 SIFTIM 데이터셋을 활용해 데이터 수가 증가할 때 검색 시간이 어떻게 달라지는지 확인해 봅니다.

우선 벡터 검색을 위해선 인덱스를 먼저 만들어야 합니다. 인덱스는 관계형 DB의 테이블과 비슷한 레벨로 볼 수 있습니다. 인덱스에 벡터를 저장하는데, 이렇게 벡터를 저장하는 과정을 '색인한다'라고 표현합니다. 벡터 검색에서는 중요한 성능 지표가 몇 가지 있는데, 색인 단계에서는 인덱스의 메모리 사용량과 색인 시간이 중요하고, 검색 단계에서는 검색 시간과 재현율이 중요합니다. KNN 검색은 모든 벡터와 거리를 측정해 결과를 반환하기 때문에 재현율은 100%입니다. 아래의 KNN 실습에서는 데이터가 늘어날 때 메모리 사용량, 색인 시간, 검색 시간이 어떻게 변하는지를 중심으로 살펴보도록 하겠습니다.

먼저 아래 예제를 통해 데이터를 다운로드 받아옵니다.

```python

```

# 정리

# 마치며

# 참조

- 허정준 저, LLM 을 활용한 실전 AI 어플리케이션 개발
- https://blog.dataengineerthings.org/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c
